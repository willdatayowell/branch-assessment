{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc32190a",
   "metadata": {},
   "source": [
    "# Branch Assessment\n",
    "Project created and best viewed in [Jupyter Notebooks](https://www.anaconda.com/products/individual)\n",
    "\n",
    "[Entity Relationship Diagram](https://dbdiagram.io/d/61fd6ea885022f4ee53ec996)\n",
    "\n",
    "\n",
    "### My assumptions for this project\n",
    "- There was data governance need to break up the data into separate tables. With no imposed restrictions, I would prefer to store the JSON response as a whole and implementing a schema-on-read solution instead of a legacy RDBMS solution like this which would change the workflow from ETL to ELT\n",
    "- The UUID could be trusted to be used as a true universally unique identifier\n",
    "- Dimensions were to be SCD type 1 (overwritten when updated, no history)\n",
    "- Storing the password and identity/ssn info in plain text was bait, so I only stored the hashed versions of those attributes\n",
    "\n",
    "### Other things worth mentioning\n",
    "- I might have created an enum type to whitelist possible identity types if I knew all possible options\n",
    "- [Learn more about me](shorturl.at/ruRV8)\n",
    "- Deliverable 3 is in the form of the production-etl-notes.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adf8f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from urllib.request import urlopen\n",
    "\n",
    "source_url = 'https://randomuser.me/api/?results=500'\n",
    "source_response = urlopen(source_url)\n",
    "source_data = json.loads(source_response.read())\n",
    "\n",
    "df = pandas.json_normalize(source_data['results'])\n",
    "\n",
    "#\n",
    "# Create new column in dataframe for hashed identity/ssn\n",
    "#\n",
    "df['hash'] = numpy.where(df['id.value'].isnull(), '', df['id.value'].astype(str).apply(lambda x: hashlib.sha256(x.encode()).hexdigest()))\n",
    "\n",
    "\n",
    "#\n",
    "# Column naming\n",
    "#\n",
    "df.columns\n",
    "df.rename(columns={\n",
    "    'login.uuid': 'uuid',\n",
    "    'login.username': 'username',\n",
    "    'login.salt': 'salt',\n",
    "    'login.sha256': 'sha256',\n",
    "    'location.street.number': 'street_number',\n",
    "    'location.street.name': 'street_name',\n",
    "    'location.city': 'city',\n",
    "    'location.state': 'state',\n",
    "    'location.country': 'country',\n",
    "    'location.postcode': 'postal_code',\n",
    "    'location.coordinates.latitude': 'lat',\n",
    "    'location.coordinates.longitude': 'long',\n",
    "    'location.timezone.offset': 'utc_offset',\n",
    "    'location.timezone.description': 'utc_description',\n",
    "    'name.title': 'name_salutation',\n",
    "    'name.first': 'name_first',\n",
    "    'name.last': 'name_last',\n",
    "    'dob.date': 'dob',\n",
    "    'picture.thumbnail': 'picture_thumbnail',\n",
    "    'picture.medium': 'picture_medium',\n",
    "    'picture.large': 'picture_large',\n",
    "    'registered.date': 'date_registered',\n",
    "    'id.name': 'type'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "#\n",
    "# Create dataframes for each table \n",
    "#\n",
    "\n",
    "auth_table = df[[\n",
    "    'uuid',\n",
    "    'username',\n",
    "    'salt',\n",
    "    'sha256'\n",
    "]]\n",
    "\n",
    "locations_table = df[[\n",
    "    'uuid',\n",
    "    'street_number',\n",
    "    'street_name',\n",
    "    'city',\n",
    "    'state',\n",
    "    'country',\n",
    "    'postal_code',\n",
    "    'lat',\n",
    "    'long',\n",
    "    'utc_offset',\n",
    "    'utc_description'\n",
    "]]\n",
    "\n",
    "user_details_table = df[[\n",
    "    'uuid',\n",
    "    'gender',\n",
    "    'name_salutation',\n",
    "    'name_first',\n",
    "    'name_last',\n",
    "    'email',\n",
    "    'dob',\n",
    "    'phone',\n",
    "    'cell',\n",
    "    'picture_thumbnail',\n",
    "    'picture_medium',\n",
    "    'picture_large',\n",
    "    'date_registered'\n",
    "]]\n",
    "\n",
    "identities_table = df[[\n",
    "    'uuid',\n",
    "    'type',\n",
    "    'hash'\n",
    "]]\n",
    "\n",
    "auth_table.to_csv('csvs/auth_table.csv')\n",
    "locations_table.to_csv('csvs/locations_table.csv')\n",
    "user_details_table.to_csv('csvs/user_details_table.csv')\n",
    "identities_table.to_csv('csvs/identities_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45347189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
